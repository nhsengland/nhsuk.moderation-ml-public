{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys\n",
        "import os\n",
        "root_path = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\" ))\n",
        "sys.path.insert(0, root_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Embeddings Multiclass Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1692204301034
        }
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sentence_transformers'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings_approach\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m embeddings_approach\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mazure_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m azure_config\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_ingestion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_ingestion\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/dg-cpu-64-core/code/Users/daniel.goldwater1/ratings-and-reviews-automod/src/embeddings_approach/embeddings_approach.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpetname\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
          ]
        }
      ],
      "source": [
        "from src.embeddings_approach import embeddings_approach\n",
        "from src.azure_config import azure_config\n",
        "from src.data_ingestion import data_ingestion\n",
        "from src.model_assessment import model_assessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692204301450
        }
      },
      "outputs": [],
      "source": [
        "# data_ingestion.add_train_test_val_labels_to_df('safeguarding_472_Sept22_DanFinola')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's just check the labels are there in the expected numbers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692204301469
        }
      },
      "outputs": [],
      "source": [
        "df = data_ingestion.DataRetrieverDatastore(\"safeguarding_472_Sept22_DanFinola\").dataset\n",
        "print(df[\"train\"].sum())\n",
        "print(df[\"test\"].sum())\n",
        "print(df[\"val\"].sum())\n",
        "del df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to make sure that the target columns exist in both the datasets we're using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692204301492
        }
      },
      "outputs": [],
      "source": [
        "run = azure_config.start_run(expeiment_name=\"embeddings_multiclass_example\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692204301508
        }
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    data_ingestion.DataRetrieverDatastore(\n",
        "        \"safeguarding_472_Sept22_DanFinola\"\n",
        "    ).dataset.columns\n",
        ")\n",
        "print(data_ingestion.DataRetrieverDatastore(\"published_3k_DG_devset\").dataset.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "They do now - but only because we've already run the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692204301528
        }
      },
      "outputs": [],
      "source": [
        "df = data_ingestion.DataRetrieverDatastore(\"safeguarding_472_Sept22_DanFinola\").dataset\n",
        "df[\"Comment Text\"] = df[\"text\"]\n",
        "data_ingestion.register_dataframe(\n",
        "    df=df, dataset_name=\"safeguarding_472_Sept22_DanFinola\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And let's make sure we've split our data into train/test/val. Again, you'll only need to do this once!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692204301550
        }
      },
      "outputs": [],
      "source": [
        "data_ingestion.add_train_test_val_labels_to_df(\n",
        "    dataset_name=\"safeguarding_472_Sept22_DanFinola\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also have to make sure that the `y` column exists in the published data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692204301566
        }
      },
      "outputs": [],
      "source": [
        "df = data_ingestion.DataRetrieverDatastore(\"published_3k_DG_devset\").dataset\n",
        "df[\"label_multi\"] = 0\n",
        "data_ingestion.register_dataframe(df=df, dataset_name=\"published_3k_DG_devset\")\n",
        "del df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OK and now onto the actual thing. \n",
        "\n",
        "Notice that, in contrast to the other example, I've used an SVM here. You have to make sure that you're using a classifier which is capable of doing multiclass. \n",
        "You also have to make sure that you're supplying the hyperopt dictionary which goes with that classifier. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692204301586
        }
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "emb_1 = embeddings_approach.EmbeddingsApproach(\n",
        "    classifier_class=sklearn.svm.SVC,\n",
        "    augmented_dataset_name_list=[],\n",
        "    # default_classifier_arguments=embeddings_approach.svm_space_arguments_default,\n",
        "    default_classifier_arguments=embeddings_approach.svm_space_arguments_default,\n",
        "    model_for_embeddings_name=\"all-MiniLM-L6-v2\",\n",
        "    name_of_column_to_embed=\"Comment Text\",\n",
        "    name_of_y_column=\"label_multi\",\n",
        "    positive_label_dataset_name_list=[\n",
        "        \"safeguarding_472_Sept22_DanFinola\",\n",
        "    ],\n",
        "    negative_label_dataset_name_list=[\"published_3k_DG_devset\"],\n",
        "    max_evals=5,\n",
        "    multiclass=True,\n",
        "    balance_train_test_val=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692204301605
        }
      },
      "outputs": [],
      "source": [
        "emb_1.find_optimised_classifier()\n",
        "emb_1.make_and_fit_optimal_classifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we've got the optimised model made, we can go ahead and some metrics and log the results. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692204301620
        }
      },
      "outputs": [],
      "source": [
        "emb_1.assessor.get_and_display_confusion_matrix()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lol, perfect! Let's log that!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692204301637
        }
      },
      "outputs": [],
      "source": [
        "emb_1.register_optimal_model()\n",
        "emb_1.log_all_attributes(run=run)\n",
        "emb_1.assessor.log_all_multiclass_metrics(run=run)\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If there are any metrics missing from the assessor class which you'd like to see registered, just add them to the class as methods!"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
